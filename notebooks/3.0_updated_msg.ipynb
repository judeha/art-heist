{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import download_url, extract_zip, HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric import EdgeIndex\n",
    "from torch_geometric.utils import add_self_loops, spmm, is_sparse\n",
    "from torch_geometric.typing import Adj, OptPairTensor, SparseTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Immutable parameters\"\"\"\n",
    "schedule_size = 100     # size of scheduling window: count discrete blocks of time\n",
    "\n",
    "# Possible qualifications for a thief\n",
    "id2qual = {\n",
    "    0: 'Safe cracking',\n",
    "    1: 'Getaway driving',\n",
    "    2: 'Masterminding',\n",
    "    3: 'Burglary',\n",
    "    4: 'Smooth Operator',\n",
    "    5: 'Hacking',\n",
    "    6: 'Token woman',\n",
    "    7: 'Flirting with detective',\n",
    "    8: 'Wisecracking',\n",
    "    9: 'Distraction'\n",
    "}\n",
    "\n",
    "# Possible factors for a thief when considering to take on a job \n",
    "id2factors = {\n",
    "    0: 'Risk',\n",
    "    1: 'Workload',\n",
    "    2: 'Payoff',\n",
    "    3: 'Complexity',\n",
    "    4: 'Travel'\n",
    "}\n",
    "\n",
    "num_quals   = len(id2qual)\n",
    "num_factors = len(id2factors)\n",
    "thief_size  = num_quals + num_factors + schedule_size # Cannot change because dimensionality of nodes cannot change\n",
    "heist_size  = 5                                       # Cannot change because dimensionality of nodes cannot change\n",
    "slot_size   = num_quals + num_factors + 1             # Cannot change because dimensionality of edges cannot change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Mutable parameters\"\"\"\n",
    "fname_pool = ['Amy','Brandon','Carli','Dante','Eleanor','Frank']\n",
    "lname_pool = ['Adams','Boxer','Charles','Darwin','Egan','Fallon']\n",
    "heist_pool = ['Vermeer','Rembrandt','Banksy','Faberge','Monet','Michelangelo','Boticelli','Van Gogh']\n",
    "museum_pool = ['British Museum', 'Smithsonian', 'Louvre', 'Billionaire\\'s Private Collection']\n",
    "\n",
    "max_heist_time = 5 # Max length of heist\n",
    "max_heist_num  = 5 # Max num of heists a thief can go on (due to union limits)\n",
    "\n",
    "qual_min = 0   # Minimum qualification level\n",
    "qual_max = 3\n",
    "\n",
    "factor_min = 0  # Minimum rating for a job factor \n",
    "factor_max = 3\n",
    "\n",
    "n_slots_min = 2 # Minimum number of slots on a job\n",
    "n_slots_max = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_schedule(n_heists):\n",
    "    \"\"\" Generate schedule for a thief \"\"\"\n",
    "\n",
    "    # initialize free (0) schedule\n",
    "    sched = np.zeros((schedule_size,))\n",
    "    if n_heists == 0:\n",
    "        return sched\n",
    "        \n",
    "    intvl = schedule_size // n_heists # prevents us from squashing all heists at end\n",
    "    max_idx = intvl\n",
    "    min_idx = 0\n",
    "    for i in range(n_heists):\n",
    "        start_idx = random.randint(min_idx, max_idx)\n",
    "        end_idx = random.randint(start_idx, max_idx)\n",
    "        sched[start_idx:end_idx] = 1\n",
    "\n",
    "        # Update intvl\n",
    "        max_idx += intvl\n",
    "        min_idx = end_idx\n",
    "    \n",
    "    return sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thief():\n",
    "    def __init__(self,\n",
    "                Id: int):\n",
    "        self.id = Id\n",
    "        self.name = f\"{random.choice(fname_pool)} {random.choice(lname_pool)}\"\n",
    "        self.schedule = generate_schedule(random.randint(0,max_heist_num))\n",
    "        self.qualifications = np.random.randint(qual_min, qual_max, size=len(id2qual))\n",
    "        currency_mask = np.random.randint(0,1,size=len(id2factors))\n",
    "        self.currencies = np.random.uniform(low=factor_min, high=factor_max, size=len(id2factors))\n",
    "        self.currencies *= currency_mask\n",
    "\n",
    "    def get_data(self):\n",
    "        # Return tensor of all data\n",
    "        data = torch.zeros((thief_size + heist_size,))\n",
    "        data[:thief_size] = torch.from_numpy(np.concatenate([self.schedule, self.qualifications, self.currencies])).to(torch.float)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Heist():\n",
    "    def __init__(self,\n",
    "                Id: int):\n",
    "        self.id = Id\n",
    "        self.name = random.choice(heist_pool)\n",
    "        self.start_time = random.randint(0, schedule_size)\n",
    "        self.end_time = random.randint(self.start_time, self.start_time + max_heist_time)\n",
    "        self.crew = {}\n",
    "        self.n_slots = random.randint(n_slots_min, n_slots_max) # num spots available  \n",
    "        self.n_slots_left = self.n_slots                        # num spots left\n",
    "        self.n_slots_required = random.randint(0,self.n_slots)  # num spots left that are required\n",
    "    \n",
    "    def get_data(self):\n",
    "                # Return tensor of all data\n",
    "        data = torch.zeros((thief_size + heist_size,))\n",
    "        data[thief_size:] = torch.from_numpy(np.array([\n",
    "            self.start_time, self.end_time, self.n_slots, self.n_slots_left, self.n_slots_required\n",
    "        ])).to(torch.float)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Slot():\n",
    "    def __init__(self,\n",
    "                Id,\n",
    "                thief_id,\n",
    "                heist_id):\n",
    "        self.id = Id\n",
    "        self.thief_id = thief_id\n",
    "        self.heist_id = heist_id\n",
    "        self.required = np.expand_dims(np.array(random.randint(0,1)), axis=0)\n",
    "        self.qualifications = np.random.randint(qual_min, qual_max, size=len(id2qual))\n",
    "        currency_mask = np.random.randint(0,1,size=len(id2factors))\n",
    "        self.currencies = np.random.uniform(low=factor_min, high=factor_max, size=len(id2factors))\n",
    "        self.currencies *= currency_mask\n",
    "\n",
    "    def get_data(self):\n",
    "        return torch.from_numpy(np.concatenate([\n",
    "            self.required, self.qualifications, self.currencies\n",
    "        ]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node dfs\n",
    "num_heists = 20\n",
    "num_thieves = 50\n",
    "\n",
    "heists_df = pd.DataFrame()\n",
    "for i in range(num_heists):\n",
    "    heist_data = Heist(i).get_data()\n",
    "    tmp_df = pd.DataFrame(heist_data.numpy()).T\n",
    "    tmp_df.index = [i]\n",
    "    # tmp_df.columns = ['start_time','end_time','n_slots','n_slots_left','n_slots_required']\n",
    "    heists_df = pd.concat([heists_df, tmp_df])\n",
    "heists_df.index.rename('heistId', inplace=True)\n",
    "\n",
    "thieves_df = pd.DataFrame()\n",
    "for i in range(num_thieves):\n",
    "    thief_data = Thief(i).get_data()\n",
    "    tmp_df = pd.DataFrame(thief_data.numpy()).T\n",
    "    tmp_df.index = [i]\n",
    "    # tmp_df.columns = ['start_time','end_time','n_slots','n_slots_left','n_slots_required']\n",
    "    thieves_df = pd.concat([thieves_df, tmp_df])\n",
    "thieves_df.index.rename('thiefId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate slots (future edge_attr) and edge index (future edge_index)\n",
    "slots_df = pd.DataFrame()\n",
    "h_lst = []  # list of heist endpoints for edges\n",
    "t_lst = []  # list of thief endpoints for edges\n",
    "\n",
    "s_idx = 0\n",
    "for h_idx, h in heists_df.iterrows():\n",
    "    for t_idx, t in thieves_df.iterrows():\n",
    "        for i in range(int(h[heist_size + thief_size - 3])):            # 112 contains n_slots data\n",
    "            # TODO: currently assign randomly\n",
    "            if random.uniform(0,1) < 0.5:\n",
    "                slot_data = Slot(s_idx, t_idx, h_idx).get_data()\n",
    "                tmp_df = pd.DataFrame(slot_data.numpy()).T\n",
    "                tmp_df.index = [s_idx]\n",
    "                slots_df = pd.concat([slots_df, tmp_df])\n",
    "                s_idx += 1\n",
    "\n",
    "                # Add endpoints\n",
    "                h_lst.append(h_idx)\n",
    "                t_lst.append(t_idx)\n",
    "slots_df.index.rename('slotId', inplace=True)\n",
    "\n",
    "# Create edge index\n",
    "edge_index_thief_to_heist = torch.stack([torch.tensor(t_lst), torch.tensor(h_lst)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: set all values to -100 for ease of identification\n",
    "thieves_df.iloc[:,:] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Add node indices\n",
    "data['thief'].node_id = torch.tensor(thieves_df.index)\n",
    "data['heist'].node_id = torch.tensor(heists_df.index)\n",
    "\n",
    "# Add node features\n",
    "data[\"thief\"].x = torch.tensor(thieves_df.values).to(torch.float)\n",
    "data[\"heist\"].x = torch.tensor(heists_df.values).to(torch.float)\n",
    "\n",
    "# Add edge indices\n",
    "data[\"thief\", \"slot\", \"heist\"].edge_index = edge_index_thief_to_heist # has shape (2, num_edges)\n",
    "\n",
    "# Add edge features\n",
    "data[\"thief\", \"slot\", \"heist\"].edge_attr = torch.tensor(slots_df.values).to(torch.float)\n",
    "\n",
    "# Add reverse edge\n",
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder sizes\n",
    "message_hidden_channels = 64\n",
    "out_channels = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, node1_in_channels = heist_size + thief_size,\n",
    "                       node2_in_channels = heist_size + thief_size,\n",
    "                       edge_in_channels  = slot_size,\n",
    "                       hidden_channels   = message_hidden_channels,\n",
    "                       out_channels      =out_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        # Define message passing layers for each type of node and edge\n",
    "        self.node1_message_passing = CustomMessagePassing(node1_in_channels)\n",
    "        self.node2_message_passing = CustomMessagePassing(node2_in_channels)\n",
    "    \n",
    "    def forward(self, data):\n",
    "\n",
    "        # Extract node features and edge attributes\n",
    "        node1_x = data['thief'].x\n",
    "        node2_x = data['heist'].x\n",
    "        edge_attr = data['thief','slot','heist'].edge_attr\n",
    "        edge_index = data['thief', 'slot', 'heist'].edge_index\n",
    "        edge_rev_index = data['heist', 'rev_slot', 'thief'].edge_index\n",
    "\n",
    "        # Embed node and edge features\n",
    "        opt_x: OptPairTensor = (node1_x, node2_x)\n",
    "        opt_x2: OptPairTensor = (node2_x, node1_x)\n",
    "\n",
    "        # Perform message passing for both node types\n",
    "        node1_messages = self.node1_message_passing(opt_x2, edge_rev_index, edge_attr)\n",
    "        # NOTE: we need to pass in OptPairTensor(neighbor_x, central_x) and the reverse edges\n",
    "        # node2_messages = self.node2_message_passing(opt_x, edge_index)\n",
    "        print(\"node1: \", node1_x.shape, \" --> \", node1_messages.shape)\n",
    "        # print(\"node2: \", node2_x.shape, \" --> \", node2_messages.shape)\n",
    "\n",
    "        return node1_messages\n",
    "\n",
    "class CustomMessagePassing(MessagePassing):\n",
    "    def __init__(self, node_channels):\n",
    "        super(CustomMessagePassing, self).__init__(aggr='mean')\n",
    "\n",
    "    def propagate(\n",
    "        self,\n",
    "        edge_index: Adj,\n",
    "        size=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        decomposed_layers = 1 if self.explain else self.decomposed_layers\n",
    "\n",
    "        for hook in self._propagate_forward_pre_hooks.values():\n",
    "            res = hook(self, (edge_index, size, kwargs))\n",
    "            if res is not None:\n",
    "                edge_index, size, kwargs = res\n",
    "\n",
    "        mutable_size = self._check_input(edge_index, size)\n",
    "\n",
    "        # Run \"fused\" message and aggregation (if applicable).\n",
    "        fuse = False\n",
    "        if self.fuse and not self.explain:\n",
    "            if is_sparse(edge_index):\n",
    "                fuse = True\n",
    "            elif (not torch.jit.is_scripting()\n",
    "                  and isinstance(edge_index, EdgeIndex)):\n",
    "                if (self.SUPPORTS_FUSED_EDGE_INDEX\n",
    "                        and edge_index.is_sorted_by_col):\n",
    "                    fuse = True\n",
    "\n",
    "        if fuse:\n",
    "            coll_dict = self._collect(self._fused_user_args, edge_index,\n",
    "                                      mutable_size, kwargs)\n",
    "\n",
    "            msg_aggr_kwargs = self.inspector.collect_param_data(\n",
    "                'message_and_aggregate', coll_dict)\n",
    "            for hook in self._message_and_aggregate_forward_pre_hooks.values():\n",
    "                res = hook(self, (edge_index, msg_aggr_kwargs))\n",
    "                if res is not None:\n",
    "                    edge_index, msg_aggr_kwargs = res\n",
    "            out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)\n",
    "            for hook in self._message_and_aggregate_forward_hooks.values():\n",
    "                res = hook(self, (edge_index, msg_aggr_kwargs), out)\n",
    "                if res is not None:\n",
    "                    out = res\n",
    "\n",
    "            update_kwargs = self.inspector.collect_param_data(\n",
    "                'update', coll_dict)\n",
    "            out = self.update(out, **update_kwargs)\n",
    "        else:  # Otherwise, run both functions in separation.\n",
    "            if decomposed_layers > 1:\n",
    "                user_args = self._user_args\n",
    "                decomp_args = {a[:-2] for a in user_args if a[-2:] == '_j'}\n",
    "                decomp_kwargs = {\n",
    "                    a: kwargs[a].chunk(decomposed_layers, -1)\n",
    "                    for a in decomp_args\n",
    "                }\n",
    "                decomp_out = []\n",
    "\n",
    "            for i in range(decomposed_layers):\n",
    "                if decomposed_layers > 1:\n",
    "                    for arg in decomp_args:\n",
    "                        kwargs[arg] = decomp_kwargs[arg][i]\n",
    "\n",
    "                coll_dict = self._collect(self._user_args, edge_index,\n",
    "                                          mutable_size, kwargs)\n",
    "\n",
    "                msg_kwargs = self.inspector.collect_param_data(\n",
    "                    'message', coll_dict)\n",
    "                for hook in self._message_forward_pre_hooks.values():\n",
    "                    res = hook(self, (msg_kwargs, ))\n",
    "                    if res is not None:\n",
    "                        msg_kwargs = res[0] if isinstance(res, tuple) else res\n",
    "                out = self.message(**msg_kwargs)\n",
    "                for hook in self._message_forward_hooks.values():\n",
    "                    res = hook(self, (msg_kwargs, ), out)\n",
    "                    if res is not None:\n",
    "                        out = res\n",
    "\n",
    "                if self.explain:\n",
    "                    explain_msg_kwargs = self.inspector.collect_param_data(\n",
    "                        'explain_message', coll_dict)\n",
    "                    out = self.explain_message(out, **explain_msg_kwargs)\n",
    "\n",
    "                aggr_kwargs = self.inspector.collect_param_data(\n",
    "                    'aggregate', coll_dict)\n",
    "                for hook in self._aggregate_forward_pre_hooks.values():\n",
    "                    res = hook(self, (aggr_kwargs, ))\n",
    "                    if res is not None:\n",
    "                        aggr_kwargs = res[0] if isinstance(res, tuple) else res\n",
    "                out = self.aggregate(out, **aggr_kwargs)\n",
    "\n",
    "                for hook in self._aggregate_forward_hooks.values():\n",
    "                    res = hook(self, (aggr_kwargs, ), out)\n",
    "                    if res is not None:\n",
    "                        out = res\n",
    "\n",
    "                update_kwargs = self.inspector.collect_param_data(\n",
    "                    'update', coll_dict)\n",
    "                out = self.update(out, **update_kwargs)\n",
    "\n",
    "                if decomposed_layers > 1:\n",
    "                    decomp_out.append(out)\n",
    "\n",
    "            if decomposed_layers > 1:\n",
    "                out = torch.cat(decomp_out, dim=-1)\n",
    "\n",
    "        for hook in self._propagate_forward_hooks.values():\n",
    "            res = hook(self, (edge_index, mutable_size, kwargs), out)\n",
    "            if res is not None:\n",
    "                out = res\n",
    "\n",
    "        print(\"Message kwargs: \", msg_kwargs)\n",
    "        print(\"Aggregation kwargs: \", aggr_kwargs)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Perform message passing for both types of nodes simultaneously\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        return x_j\n",
    "\n",
    "    def aggregate(self, inputs, index, ptr = None, dim_size = None):\n",
    "        # inputs has shape [E, hidden]\n",
    "        # index has shape [E]\n",
    "        # NOTE: output has shape [N1, H] where N1 = num of nodes of opposite type\n",
    "        print(\"Aggregation inputs: dim_size=\", dim_size, \", inputs=\", inputs.shape)\n",
    "\n",
    "        return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,\n",
    "                                dim=self.node_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation inputs: dim_size= 50 , inputs= torch.Size([2560, 120])\n",
      "Message kwargs:  {'x_i': tensor([[-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        ...,\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.],\n",
      "        [-100., -100., -100.,  ..., -100., -100., -100.]]), 'x_j': tensor([[0., 0., 0.,  ..., 4., 4., 0.],\n",
      "        [0., 0., 0.,  ..., 4., 4., 0.],\n",
      "        [0., 0., 0.,  ..., 4., 4., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 5., 5., 2.],\n",
      "        [0., 0., 0.,  ..., 5., 5., 2.],\n",
      "        [0., 0., 0.,  ..., 5., 5., 2.]]), 'edge_attr': tensor([[1., 1., 2.,  ..., 0., 0., 0.],\n",
      "        [1., 2., 2.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 2., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 2., 2.,  ..., 0., 0., 0.]])}\n",
      "Aggregation kwargs:  {'index': tensor([ 0,  0,  1,  ..., 48, 48, 49]), 'ptr': None, 'dim_size': 50}\n",
      "node1:  torch.Size([50, 120])  -->  torch.Size([50, 120])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GNN model\n",
    "model = GNN()\n",
    "\n",
    "# Forward pass with the data\n",
    "output = model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, 31.7255, 33.7451,  5.9020,  5.9020,  3.5882])\n"
     ]
    }
   ],
   "source": [
    "# Message passing result for model above for node1 (thief)\n",
    "print(output[0])\n",
    "\n",
    "\"\"\" Can we get to the same result manually? \n",
    "Remember:\n",
    "- thief = node1\n",
    "- heist = node2\n",
    "- edge_index = data['thief','slot','heist].edge_index\n",
    "\n",
    "Message method calculates messages for EVERY edge\n",
    "Agg method determines which ones to take for agg\n",
    "- 'index' kwarg is edge_index[1] and has values from 0-49\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reverse edge index\n",
    "edge_rev_index = data['heist','rev_slot','thief'].edge_index[1]\n",
    "\n",
    "# Get data\n",
    "node1_x = data['thief'].x\n",
    "node2_x = data['heist'].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices where the edge is connected to thief 0\n",
    "idx = (edge_rev_index==0).nonzero()\n",
    "\n",
    "# Get the other endpoints of edges connected to thief 0 -> heists that thief 0 is connected to\n",
    "heist_idx = data['heist','rev_slot','thief'].edge_index[0][idx]\n",
    "\n",
    "# Calculate mean values of these heists (since agg method = mean)\n",
    "heist_sum = 0\n",
    "for i in heist_idx:\n",
    "    heist_sum += node2_x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000, 31.7255, 33.7451,  5.9020,  5.9020,  3.5882]])\n"
     ]
    }
   ],
   "source": [
    "print(heist_sum / len(heist_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building up GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder sizes\n",
    "encoder_node1_channels = [heist_size + thief_size, 128, 32]\n",
    "encoder_node2_channels = [heist_size + thief_size, 128, 32]\n",
    "encoder_edge_channels = [slot_size, 16, 8]\n",
    "\n",
    "# Message passing sizes\n",
    "message_hidden_channels = 64\n",
    "out_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, encoder_node1_channels  : list = encoder_node1_channels,\n",
    "                       encoder_node2_channels  : list = encoder_node2_channels,\n",
    "                       encoder_edge_channels   : list = encoder_edge_channels,\n",
    "                       message_hidden_channels : int  = message_hidden_channels, # Latent space message passing happens in\n",
    "                       out_channels            : int  = out_channels,\n",
    "                       n_passes                : int  = 3):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        node1_in, node1_h, node1_out = encoder_node1_channels\n",
    "        node2_in, node2_h, node2_out = encoder_node2_channels\n",
    "        edge_in,  edge_h,  edge_out  = encoder_edge_channels\n",
    "        self.node1_encoder = Encoder(node1_in, node1_h, node1_out)\n",
    "        self.node2_encoder = Encoder(node2_in, node2_h, node2_out)\n",
    "        self.edge_encoder  = Encoder(edge_in, edge_h, edge_out)\n",
    "\n",
    "        # Define message passing layers -> take in the output sizes of the encoders\n",
    "        self.n_passes = n_passes\n",
    "        self.node1_message_passing = CustomMessagePassing(node1_out, message_hidden_channels, edge_size=edge_out)\n",
    "        self.node2_message_passing = CustomMessagePassing(node2_out, message_hidden_channels, edge_size=edge_out)\n",
    "        self.edge_message_passing  = EdgeMessagePassing(edge_out, node1_out, node2_out, message_hidden_channels)\n",
    "\n",
    "        # Define final linear transformation layer\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(edge_out, 2*edge_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*edge_out, out_channels)\n",
    "        )\n",
    "\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Linear(edge_out + node1_out + node2_out, 2*edge_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*edge_out, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "\n",
    "        # Extract node features and edge attributes\n",
    "        node1_x = data['thief'].x\n",
    "        node2_x = data['heist'].x\n",
    "        edge_attr = data['thief','slot','heist'].edge_attr\n",
    "        edge_index = data['thief', 'slot', 'heist'].edge_index\n",
    "        edge_rev_index = data['heist', 'rev_slot', 'thief'].edge_index\n",
    "\n",
    "        # Embed node and edge features\n",
    "        node1_x = self.node1_encoder(node1_x)\n",
    "        node2_x = self.node2_encoder(node2_x)\n",
    "        edge_x = self.edge_encoder(edge_attr)\n",
    "        # print(node1_x.shape) # 50, 32\n",
    "        # print(node2_x.shape) # 20, 32\n",
    "        # print(edge_x.shape) # E, 8\n",
    "\n",
    "        # Preserve original embeddings\n",
    "        node1_x_original = node1_x\n",
    "        node2_x_original = node2_x\n",
    "        edge_x_original  = edge_x\n",
    "\n",
    "        # Perform n message passing\n",
    "        for i in range(self.n_passes):\n",
    "            opt_x: OptPairTensor = (node1_x, node2_x)\n",
    "            opt_x2: OptPairTensor = (node2_x, node1_x)\n",
    "\n",
    "            node1_x = self.node1_message_passing(edge_rev_index, opt_x2, edge_x)\n",
    "            node2_x = self.node2_message_passing(edge_index, opt_x, edge_x)\n",
    "            edge_x  = self.edge_message_passing(edge_index, edge_x, node1_x, node2_x)\n",
    "\n",
    "        print(\"Original --> Embedding --> Message passing\")\n",
    "        print(\"node1: \", data['thief'].x.shape, \" --> \", node1_x_original.shape, \" --> \", node1_x.shape)\n",
    "        print(\"node2: \", data['heist'].x.shape, \" --> \", node2_x_original.shape, \" --> \", node2_x.shape)\n",
    "        print(\"edge: \", edge_attr.shape, \" --> \", edge_x_original.shape, \" --> \", edge_x.shape)\n",
    "\n",
    "        # Combine with preserved embeddings\n",
    "        node1_x += node1_x_original\n",
    "        node2_x += node2_x_original\n",
    "        edge_x += edge_x_original\n",
    "\n",
    "        # Final decoding, version 0 -> just pass edge through mlp\n",
    "        out = self.decoder(edge_x)\n",
    "        print(out.shape)\n",
    "\n",
    "        # Final decoding, version 1 -> dot product endpoints, then pass through mlp\n",
    "        src, dst = edge_index\n",
    "        out = (node1_x[src] * node2_x[dst]).sum(dim=-1)\n",
    "        print(out.shape)\n",
    "\n",
    "        # Final decoding, version 2 -> pass edge + endpoints through mlp\n",
    "        out = self.decoder2(torch.cat([edge_x, node1_x[src], node2_x[dst]], dim=1))\n",
    "        print(out.shape)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" 2 layer MLP \"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class CustomMessagePassing(MessagePassing):\n",
    "    def __init__(self, node_channels,\n",
    "                       message_hidden_channels,\n",
    "                       edge_size=None):\n",
    "        super(CustomMessagePassing, self).__init__(aggr='mean')\n",
    "        \n",
    "        \"\"\" \n",
    "        Message passing layer shape: node_channels + edge_size -> message_hidden_channels -> node_channels\n",
    "        - outputs same size for iterated passing\n",
    "        \"\"\"\n",
    "\n",
    "        # Define linear transformations for message passing\n",
    "        in_size = node_channels + (edge_size if edge_size is not None else 0)\n",
    "        self.neighbor_linear = nn.Linear(in_size, message_hidden_channels)\n",
    "        self.update_linear = nn.Linear(message_hidden_channels, node_channels) # TODO: consider changing dimensions\n",
    "\n",
    "    def forward(self, edge_index, x, edge_attr=None):\n",
    "        # Perform message passing for both types of nodes simultaneously\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr=None):\n",
    "        # x_i has shape [E, central_node_dim]\n",
    "        # x_j has shape [E, neighbor_node_dim]\n",
    "        # edge_attr has shape [E, slot_dim]\n",
    "\n",
    "        # Apply linear transformation for edge messages\n",
    "        if edge_attr is not None:\n",
    "            tmp = torch.cat([x_j,edge_attr],dim=1)\n",
    "        else: tmp = x_j\n",
    "        return self.neighbor_linear(tmp)\n",
    "    \n",
    "    def update(self, aggr_out):\n",
    "        # Apply linear transformation for node messages\n",
    "        return self.update_linear(aggr_out)\n",
    "    \n",
    "class EdgeMessagePassing(nn.Module):\n",
    "    def __init__(self, edge_channels,\n",
    "                       node1_channels,\n",
    "                       node2_channels,\n",
    "                       hidden_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "             nn.Linear(edge_channels + node1_channels + node2_channels, hidden_channels),\n",
    "             nn.ReLU(),\n",
    "             nn.Linear(hidden_channels, edge_channels) # outputs same size for iterated passing\n",
    "        )\n",
    "\n",
    "    def forward(self, edge_index, edge_attr, node1, node2):\n",
    "        # No need for aggr, update since num nodes for each edge is constant at 2\n",
    "        row, col  = edge_index\n",
    "        new_edge_attr = self.mlp(torch.cat([node1[row], node2[col], edge_attr], dim=-1))\n",
    "        return new_edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original --> Embedding --> Message passing\n",
      "node1:  torch.Size([50, 120])  -->  torch.Size([50, 32])  -->  torch.Size([50, 32])\n",
      "node2:  torch.Size([20, 120])  -->  torch.Size([20, 32])  -->  torch.Size([20, 32])\n",
      "edge:  torch.Size([2560, 16])  -->  torch.Size([2560, 8])  -->  torch.Size([2560, 8])\n",
      "torch.Size([2560, 1])\n",
      "torch.Size([50, 32]) tensor([ 0,  0,  1,  ..., 48, 48, 49])\n",
      "torch.Size([2560])\n",
      "torch.Size([2560, 1])\n"
     ]
    }
   ],
   "source": [
    "model = GNN()\n",
    "\n",
    "output = model(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
