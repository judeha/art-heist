{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import download_url, extract_zip, HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import add_self_loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_pool = ['Amy','Brandon','Carli','Dante','Eleanor','Frank']\n",
    "lname_pool = ['Adams','Boxer','Charles','Darwin','Egan','Fallon']\n",
    "heist_pool = ['Vermeer','Rembrandt','Banksy','Faberge Egg']\n",
    "\n",
    "schedule_size = 100\n",
    "max_heist_time = 5\n",
    "num_heist = 5\n",
    "\n",
    "qual_min = 0\n",
    "qual_max = 3\n",
    "curr_min = 0\n",
    "curr_max = 3\n",
    "\n",
    "n_slots_min = 2\n",
    "n_slots_max = 8\n",
    "\n",
    "id2qual = {\n",
    "    0: 'Safe Cracker',\n",
    "    1: 'Getaway Driver',\n",
    "    2: 'Mastermind',\n",
    "    3: 'Cat Burglar',\n",
    "    4: 'Smooth Operator',\n",
    "    5: 'Hacker'\n",
    "}\n",
    "\n",
    "id2currency = {\n",
    "    0: 'Risk',\n",
    "    1: 'Workload',\n",
    "    2: 'Payoff',\n",
    "    3: 'Artistic Enjoyment',\n",
    "}\n",
    "\n",
    "def generate_schedule(num_heists):\n",
    "    sched = np.zeros((schedule_size,))\n",
    "    if num_heists == 0:\n",
    "        return sched\n",
    "        \n",
    "    intvl = schedule_size // num_heists # prevents us from squashing all heists at end\n",
    "    max_idx = intvl\n",
    "    min_idx = 0\n",
    "    for i in range(num_heists):\n",
    "        start_idx = random.randint(min_idx, max_idx)\n",
    "        end_idx = random.randint(start_idx, max_idx)\n",
    "        sched[start_idx:end_idx] = 1\n",
    "\n",
    "        # Update intvl\n",
    "        max_idx += intvl\n",
    "        min_idx = end_idx\n",
    "    \n",
    "    return sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thief_size = 110\n",
    "heist_size = 5\n",
    "slot_size = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thief():\n",
    "    def __init__(self,\n",
    "                Id: int):\n",
    "        self.id = Id\n",
    "        self.name = f\"{random.choice(fname_pool)} {random.choice(lname_pool)}\"\n",
    "        self.schedule = generate_schedule(random.randint(0,num_heists))\n",
    "        self.qualifications = np.random.randint(qual_min, qual_max, size=len(id2qual))\n",
    "        currency_mask = np.random.randint(0,1,size=len(id2currency))\n",
    "        self.currencies = np.random.uniform(low=curr_min, high=curr_max, size=len(id2currency))\n",
    "        self.currencies *= currency_mask\n",
    "\n",
    "    def get_data(self):\n",
    "        # Return tensor of all data\n",
    "        data = torch.zeros((thief_size + heist_size,))\n",
    "        data[:thief_size] = torch.from_numpy(np.concatenate([self.schedule, self.qualifications, self.currencies])).to(torch.float)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Heist():\n",
    "    def __init__(self,\n",
    "                Id: int):\n",
    "        self.id = Id\n",
    "        self.name = random.choice(heist_pool)\n",
    "        self.start_time = random.randint(0, schedule_size)\n",
    "        self.end_time = random.randint(self.start_time, self.start_time + max_heist_time)\n",
    "        self.crew = {}\n",
    "        self.n_slots = random.randint(n_slots_min, n_slots_max) # num spots available  \n",
    "        self.n_slots_left = self.n_slots                        # num spots left\n",
    "        self.n_slots_required = random.randint(0,self.n_slots)  # num spots left that are required\n",
    "    \n",
    "    def get_data(self):\n",
    "                # Return tensor of all data\n",
    "        data = torch.zeros((thief_size + heist_size,))\n",
    "        data[thief_size:] = torch.from_numpy(np.array([\n",
    "            self.start_time, self.end_time, self.n_slots, self.n_slots_left, self.n_slots_required\n",
    "        ])).to(torch.float)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Slot():\n",
    "    def __init__(self,\n",
    "                Id,\n",
    "                thief_id,\n",
    "                heist_id):\n",
    "        self.id = Id\n",
    "        self.thief_id = thief_id\n",
    "        self.heist_id = heist_id\n",
    "        self.required = np.expand_dims(np.array(random.randint(0,1)), axis=0)\n",
    "        self.qualifications = np.random.randint(qual_min, qual_max, size=len(id2qual))\n",
    "        currency_mask = np.random.randint(0,1,size=len(id2currency))\n",
    "        self.currencies = np.random.uniform(low=curr_min, high=curr_max, size=len(id2currency))\n",
    "        self.currencies *= currency_mask\n",
    "\n",
    "    def get_data(self):\n",
    "        return torch.from_numpy(np.concatenate([\n",
    "            self.required, self.qualifications, self.currencies\n",
    "        ]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node dfs\n",
    "num_heists = 20\n",
    "num_thieves = 50\n",
    "\n",
    "heists_df = pd.DataFrame()\n",
    "for i in range(num_heists):\n",
    "    heist_data = Heist(i).get_data()\n",
    "    tmp_df = pd.DataFrame(heist_data.numpy()).T\n",
    "    tmp_df.index = [i]\n",
    "    # tmp_df.columns = ['start_time','end_time','n_slots','n_slots_left','n_slots_required']\n",
    "    heists_df = pd.concat([heists_df, tmp_df])\n",
    "heists_df.index.rename('heistId', inplace=True)\n",
    "\n",
    "thieves_df = pd.DataFrame()\n",
    "for i in range(num_thieves):\n",
    "    thief_data = Thief(i).get_data()\n",
    "    tmp_df = pd.DataFrame(thief_data.numpy()).T\n",
    "    tmp_df.index = [i]\n",
    "    # tmp_df.columns = ['start_time','end_time','n_slots','n_slots_left','n_slots_required']\n",
    "    thieves_df = pd.concat([thieves_df, tmp_df])\n",
    "thieves_df.index.rename('thiefId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate slots (future edge_attr) and edge index (future edge_index)\n",
    "slots_df = pd.DataFrame()\n",
    "h_lst = []  # list of heist endpoints for edges\n",
    "t_lst = []  # list of thief endpoints for edges\n",
    "\n",
    "s_idx = 0\n",
    "for h_idx, h in heists_df.iterrows():\n",
    "    for t_idx, t in thieves_df.iterrows():\n",
    "        for i in range(int(h[112])):            # 112 contains n_slots data\n",
    "            # TODO: currently assign randomly\n",
    "            if random.uniform(0,1) < 0.5:\n",
    "                slot_data = Slot(s_idx, t_idx, h_idx).get_data()\n",
    "                tmp_df = pd.DataFrame(slot_data.numpy()).T\n",
    "                tmp_df.index = [s_idx]\n",
    "                slots_df = pd.concat([slots_df, tmp_df])\n",
    "                s_idx += 1\n",
    "\n",
    "                # Add endpoints\n",
    "                h_lst.append(h_idx)\n",
    "                t_lst.append(t_idx)\n",
    "slots_df.index.rename('slotId', inplace=True)\n",
    "\n",
    "# Create edge index\n",
    "edge_index_thief_to_heist = torch.stack([torch.tensor(t_lst), torch.tensor(h_lst)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Add node indices\n",
    "data['thief'].node_id = torch.tensor(thieves_df.index)\n",
    "data['heist'].node_id = torch.tensor(heists_df.index)\n",
    "\n",
    "# Add node features\n",
    "data[\"thief\"].x = torch.tensor(thieves_df.values).to(torch.float)\n",
    "data[\"heist\"].x = torch.tensor(heists_df.values).to(torch.float)\n",
    "\n",
    "# Add edge indices\n",
    "data[\"thief\", \"slot\", \"heist\"].edge_index = edge_index_thief_to_heist # has shape (2, num_edges)\n",
    "\n",
    "# Add edge features\n",
    "data[\"thief\", \"slot\", \"heist\"].edge_attr = torch.tensor(slots_df.values).to(torch.float)\n",
    "\n",
    "# Add reverse edge\n",
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src, dst = edge_index\n",
    "score = (x[src] * x[dst]).sum(dim=-1)\n",
    "\n",
    "row, col = edge_index\n",
    "new_edge_attr = self.mlp(torch.cat([x[row], x[col], edge_attr], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Slots and people as nodes\n",
    "Edge is the assignment decision\n",
    "Softly represent fullness of a flight through an embedding\n",
    "- duplicate event doesn't matter\n",
    "- hard constraints can be solved through environment itself. don't let environment until all seats are filled\n",
    "- loosely using the term positional embedding. dot product between seats on same flight = 1\n",
    "- edge between events? \n",
    "- temporal embedding: Hope that implicitly it learns it!!!\n",
    "Recommendation: dot product of describing seat + dot product of positional\n",
    "- use sinusoidal function for embedding vector???\n",
    "\n",
    "Nick libertini: two different images, matching them using key points\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message passing sizes\n",
    "in_node1_channels = 115\n",
    "in_node2_channels = 115\n",
    "in_edge_channels = 11\n",
    "\n",
    "hidden_channels = 64\n",
    "out_channels = 1\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, in_node1_channels=in_node1_channels,\n",
    "                       in_node2_channels=in_node2_channels,\n",
    "                       in_edge_channels =in_edge_channels,\n",
    "                       hidden_channels  =hidden_channels,\n",
    "                       out_channels     =out_channels):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # TODO: add encoding\n",
    "        # TODO: add edge updates\n",
    "        # TODO: add edge regression\n",
    "\n",
    "        # Define message passing layers for each type of node and edge\n",
    "        self.node1_message_passing = CustomMessagePassing(in_node1_channels, in_edge_channels, hidden_channels)\n",
    "        self.node2_message_passing = CustomMessagePassing(in_node2_channels, in_edge_channels, hidden_channels)\n",
    "\n",
    "        # Define final linear transformation layer\n",
    "        self.linear = nn.Linear(hidden_channels, out_channels) # TODO: hidden_channels * 2?\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        # Extract node features and edge attributes\n",
    "        node1_x = data['thief'].x\n",
    "        node2_x = data['heist'].x\n",
    "        edge_attr = data['thief', 'slot', 'heist'].edge_attr\n",
    "        edge_index = data['thief', 'slot', 'heist'].edge_index\n",
    "        edge_rev_index = data['heist', 'rev_slot', 'thief'].edge_index\n",
    "\n",
    "\n",
    "        # Perform message passing for both node types\n",
    "        node1_messages = self.node1_message_passing(node1_x, edge_attr, edge_index)\n",
    "        node2_messages = self.node2_message_passing(node2_x, edge_attr, edge_rev_index)\n",
    "        # print(node1_messages.shape) # 20, 64\n",
    "        # print(node2_messages.shape) # 50, 64\n",
    "\n",
    "        combined_messages = torch.cat([node1_messages, node2_messages], dim=0)\n",
    "        print(combined_messages.shape)\n",
    "\n",
    "        # Apply final linear transformation\n",
    "        out = self.linear(combined_messages)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CustomMessagePassing(MessagePassing):\n",
    "    def __init__(self, node_channels,\n",
    "                       edge_channels,\n",
    "                       out_channels):\n",
    "        super(CustomMessagePassing, self).__init__(aggr='mean')\n",
    "\n",
    "        # Define linear transformations for message passing\n",
    "        # self.node_linear = nn.Linear(in_channels, out_channels)\n",
    "        self.neighbor_linear = nn.Linear(node_channels + edge_channels, out_channels)\n",
    "        # self.edge_linear = nn.Linear(edge_channels + 2*in_channels, out_channels)\n",
    "        self.update_linear = nn.Linear(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index):\n",
    "        # Perform message passing for both types of nodes simultaneously\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_i has shape [E, thief_dim]\n",
    "        # x_j has shape [E, heist_dim]\n",
    "        # edge_attr has shape [E, slot_dim]\n",
    "\n",
    "        # Apply linear transformation for edge messages\n",
    "        tmp = torch.cat([x_j,edge_attr],dim=1)\n",
    "        return self.neighbor_linear(tmp)\n",
    "\n",
    "    \n",
    "    def aggregate(self, inputs, index, ptr = None, dim_size = None):\n",
    "        # inputs has shape [E, hidden]\n",
    "        # index has shape [E]\n",
    "        # NOTE: output has shape [N1, H] where N1 = num of nodes of opposite type\n",
    "        return self.aggr_module(inputs, index, ptr=ptr, dim_size=None, # TODO: had to set dim_size to None\n",
    "                                dim=self.node_dim)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Apply linear transformation for node messages\n",
    "        return self.update_linear(aggr_out)\n",
    "\n",
    "\n",
    "# NOTE 1: use the reverse edges\n",
    "# NOTE 2: need to set dim_size in agg to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70, 64])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GNN model\n",
    "model = GNN(in_node1_channels, in_node2_channels, in_edge_channels, hidden_channels, out_channels)\n",
    "\n",
    "# Forward pass with the data\n",
    "output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder sizes\n",
    "encoder_node1_channels = [115, 128, 64]\n",
    "encoder_node2_channels = [115, 128, 64]\n",
    "encoder_edge_channels = [11, 16, 8]\n",
    "\n",
    "# Message passing sizes\n",
    "message_hidden_channels = 64\n",
    "out_channels = 1\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, encoder_node1_channels: list = encoder_node1_channels,\n",
    "                       encoder_node2_channels: list = encoder_node2_channels,\n",
    "                       encoder_edge_channels : list = encoder_edge_channels,\n",
    "                       hidden_channels  =hidden_channels,\n",
    "                       out_channels     =out_channels):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # TODO: add edge updates\n",
    "        # TODO: add edge regression\n",
    "\n",
    "        node1_in, node1_h, node1_out = encoder_node1_channels\n",
    "        node2_in, node2_h, node2_out = encoder_node2_channels\n",
    "        edge_in, edge_h, edge_out = encoder_edge_channels # NOTE: the output of the embedding is the input size to the message passing\n",
    "        self.node1_encoder = Encoder(node1_in, node1_h, node1_out)\n",
    "        self.node2_encoder = Encoder(node2_in, node2_h, node2_out)\n",
    "        self.edge_encoder  = Encoder(edge_in, edge_h, edge_out)\n",
    "\n",
    "        # Define message passing layers for each type of node and edge\n",
    "        self.node1_message_passing = CustomMessagePassing(node1_out, edge_out, hidden_channels)\n",
    "        self.node2_message_passing = CustomMessagePassing(node2_out, edge_out, hidden_channels)\n",
    "\n",
    "        # Define final linear transformation layer\n",
    "        self.linear = nn.Linear(hidden_channels, out_channels) # TODO: hidden_channels * 2?\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        # Extract node features and edge attributes\n",
    "        node1_x = data['thief'].x\n",
    "        node2_x = data['heist'].x\n",
    "        edge_attr = data['thief', 'slot', 'heist'].edge_attr\n",
    "        edge_index = data['thief', 'slot', 'heist'].edge_index\n",
    "        edge_rev_index = data['heist', 'rev_slot', 'thief'].edge_index\n",
    "\n",
    "        # Embed node and edge features\n",
    "        node1_x = self.node1_encoder(node1_x)\n",
    "        node2_x = self.node2_encoder(node2_x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "        # print(node1_x.shape) # 50, 64\n",
    "        # print(node2_x.shape) # 20, 64\n",
    "        # print(edge_attr.shape) # E, 8\n",
    "\n",
    "        # Perform message passing for both node types\n",
    "        node1_messages = self.node1_message_passing(node1_x, edge_attr, edge_index)\n",
    "        node2_messages = self.node2_message_passing(node2_x, edge_attr, edge_rev_index)\n",
    "        # print(node1_messages.shape) # 20, 64\n",
    "        # print(node2_messages.shape) # 50, 64\n",
    "        \n",
    "        # Perform message passing for edge\n",
    "\n",
    "        combined_messages = torch.cat([node1_messages, node2_messages], dim=0)\n",
    "\n",
    "        # Apply final linear transformation\n",
    "        out = self.linear(combined_messages)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class CustomMessagePassing(MessagePassing):\n",
    "    def __init__(self, node_channels,\n",
    "                       edge_channels,\n",
    "                       out_channels):\n",
    "        super(CustomMessagePassing, self).__init__(aggr='mean')\n",
    "\n",
    "        # Define linear transformations for message passing\n",
    "        # self.node_linear = nn.Linear(in_channels, out_channels)\n",
    "        self.neighbor_linear = nn.Linear(node_channels + edge_channels, out_channels)\n",
    "        # self.edge_linear = nn.Linear(edge_channels + 2*in_channels, out_channels)\n",
    "        self.update_linear = nn.Linear(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index):\n",
    "        # Perform message passing for both types of nodes simultaneously\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_i has shape [E, thief_dim]\n",
    "        # x_j has shape [E, heist_dim]\n",
    "        # edge_attr has shape [E, slot_dim]\n",
    "\n",
    "        # Apply linear transformation for edge messages\n",
    "        tmp = torch.cat([x_j,edge_attr],dim=1)\n",
    "        return self.neighbor_linear(tmp)\n",
    "\n",
    "        # TODO: will this have 0 neighbors, since I only pass in one node type at a time?\n",
    "    \n",
    "    def aggregate(self, inputs, index, ptr = None, dim_size = None):\n",
    "        # inputs has shape [E, hidden]\n",
    "        # index has shape [E]\n",
    "        # NOTE: output has shape [N1, H] where N1 = num of nodes of opposite type\n",
    "        return self.aggr_module(inputs, index, ptr=ptr, dim_size=None, # TODO: had to set dim_size to None\n",
    "                                dim=self.node_dim)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Apply linear transformation for node messages\n",
    "        return self.update_linear(aggr_out)\n",
    "\n",
    "\n",
    "# NOTE 1: use the reverse edges\n",
    "# NOTE 2: need to set dim_size in agg to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1934, 64])\n",
      "torch.Size([1934, 64])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GNN model\n",
    "model = GNN()\n",
    "\n",
    "# Forward pass with the data\n",
    "output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder sizes\n",
    "encoder_node1_channels = [115, 128, 64]\n",
    "encoder_node2_channels = [115, 128, 64]\n",
    "encoder_edge_channels = [11, 16, 8]\n",
    "\n",
    "# Message passing sizes\n",
    "message_hidden_channels = 64\n",
    "out_channels = 1\n",
    "\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, encoder_node1_channels: list = encoder_node1_channels,\n",
    "                       encoder_node2_channels: list = encoder_node2_channels,\n",
    "                       encoder_edge_channels : list = encoder_edge_channels,\n",
    "                       hidden_channels  =hidden_channels,\n",
    "                       out_channels     =out_channels):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        node1_in, node1_h, node1_out = encoder_node1_channels\n",
    "        node2_in, node2_h, node2_out = encoder_node2_channels\n",
    "        edge_in, edge_h, edge_out = encoder_edge_channels # NOTE: the output of the embedding is the input size to the message passing\n",
    "        self.node1_encoder = Encoder(node1_in, node1_h, node1_out)\n",
    "        self.node2_encoder = Encoder(node2_in, node2_h, node2_out)\n",
    "        self.edge_encoder  = Encoder(edge_in, edge_h, edge_out)\n",
    "\n",
    "        # Define message passing layers for each type of node and edge\n",
    "        self.node1_message_passing = CustomMessagePassing(node1_out, edge_out, hidden_channels)\n",
    "        self.node2_message_passing = CustomMessagePassing(node2_out, edge_out, hidden_channels)\n",
    "        self.edge_message_passing  = EdgeMessagePassing(edge_out, hidden_channels, hidden_channels, 2*hidden_channels, hidden_channels)\n",
    "\n",
    "        # Define final linear transformation layer\n",
    "        self.linear = nn.Linear(hidden_channels, out_channels) # TODO: hidden_channels * 2?\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        # Extract node features and edge attributes\n",
    "        node1_x = data['thief'].x\n",
    "        node2_x = data['heist'].x\n",
    "        edge_attr = data['thief', 'slot', 'heist'].edge_attr\n",
    "        edge_index = data['thief', 'slot', 'heist'].edge_index\n",
    "        edge_rev_index = data['heist', 'rev_slot', 'thief'].edge_index\n",
    "\n",
    "        # Embed node and edge features\n",
    "        node1_x = self.node1_encoder(node1_x)\n",
    "        node2_x = self.node2_encoder(node2_x)\n",
    "        edge_x = self.edge_encoder(edge_attr)\n",
    "        # print(node1_x.shape) # 50, 64\n",
    "        # print(node2_x.shape) # 20, 64\n",
    "        # print(edge_attr.shape) # E, 8\n",
    "\n",
    "        # Perform message passing for both node types\n",
    "        node1_messages = self.node1_message_passing(node1_x, edge_x, edge_index)\n",
    "        node2_messages = self.node2_message_passing(node2_x, edge_x, edge_rev_index)\n",
    "        # print(node1_messages.shape) # 20, 64\n",
    "        # print(node2_messages.shape) # 50, 64\n",
    "        \n",
    "        # Perform message passing for edge\n",
    "        edge_messages = self.edge_message_passing(edge_x, node2_messages, node1_messages, edge_index)\n",
    "        # Reverse node2 and node1 because we're using messages, not direct embeddings\n",
    "        assert edge_messages.shape == (edge_x.shape[0], hidden_channels)\n",
    "        # TODO: is 64 too big for edge message?\n",
    "\n",
    "        # combined_messages = torch.cat([node1_messages, node2_messages], dim=0)\n",
    "        # print(combined_messages.shape)\n",
    "\n",
    "        # Apply final linear transformation\n",
    "        out = self.linear(edge_messages)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class CustomMessagePassing(MessagePassing):\n",
    "    def __init__(self, node_channels,\n",
    "                       edge_channels,\n",
    "                       out_channels):\n",
    "        super(CustomMessagePassing, self).__init__(aggr='mean')\n",
    "\n",
    "        # Define linear transformations for message passing\n",
    "        self.neighbor_linear = nn.Linear(node_channels + edge_channels, out_channels)\n",
    "        self.update_linear = nn.Linear(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index):\n",
    "        # Perform message passing for both types of nodes simultaneously\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # x_i has shape [E, thief_dim]\n",
    "        # x_j has shape [E, heist_dim]\n",
    "        # edge_attr has shape [E, slot_dim]\n",
    "\n",
    "        # Apply linear transformation for edge messages\n",
    "        tmp = torch.cat([x_j,edge_attr],dim=1)\n",
    "        return self.neighbor_linear(tmp)\n",
    "\n",
    "    \n",
    "    def aggregate(self, inputs, index, ptr = None, dim_size = None):\n",
    "        # inputs has shape [E, hidden]\n",
    "        # index has shape [E]\n",
    "        # NOTE: output has shape [N1, H] where N1 = num of nodes of opposite type\n",
    "        return self.aggr_module(inputs, index, ptr=ptr, dim_size=None, # TODO: had to set dim_size to None\n",
    "                                dim=self.node_dim)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Apply linear transformation for node messages\n",
    "        return self.update_linear(aggr_out)\n",
    "\n",
    "class EdgeMessagePassing(nn.Module):\n",
    "    def __init__(self, edge_channels,\n",
    "                       node1_channels,\n",
    "                       node2_channels,\n",
    "                       hidden_channels, # input as 2 * hidden_channels above\n",
    "                       out_channels):   # input as hidden_channels above\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "             nn.Linear(edge_channels + node1_channels + node2_channels, hidden_channels),\n",
    "             nn.ReLU(),\n",
    "             nn.Linear(hidden_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, edge_attr, node1, node2, edge_index):\n",
    "        # No need for aggr, update since num nodes for each edge is constant at 2\n",
    "        row, col  = edge_index\n",
    "        new_edge_attr = self.mlp(torch.cat([node1[row], node2[col], edge_attr], dim=-1))\n",
    "        return new_edge_attr\n",
    "\n",
    "# NOTE 1: use the reverse edges\n",
    "# NOTE 2: need to set dim_size in agg to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the GNN model\n",
    "model = GNN()\n",
    "\n",
    "# Forward pass with the data\n",
    "output = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90057"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
